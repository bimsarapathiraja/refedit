{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_decode(encoded_mask, base_image_path):\n",
    "    \n",
    "    org_image_path = base_image_path.replace(\"_512\", \"\")\n",
    "\n",
    "    org_image = Image.open(org_image_path)\n",
    "    org_image_size = org_image.size\n",
    "    \n",
    "    # Create a blank image\n",
    "    new_mask = Image.new('L', org_image_size, 0)\n",
    "    new_draw = ImageDraw.Draw(new_mask)\n",
    "\n",
    "    # Draw the polygon\n",
    "    new_draw.polygon(encoded_mask, outline=1, fill=1)\n",
    "\n",
    "    # Convert to numpy array for further processing if needed\n",
    "    new_mask_array = np.array(new_mask)\n",
    "    \n",
    "    new_mask_array = cv2.resize(new_mask_array, (512, 512))\n",
    "    \n",
    "    new_mask_array = cv2.dilate(new_mask_array, np.ones((15, 15), np.uint8), iterations=1)\n",
    "    \n",
    "    return new_mask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(ckpt_pth):\n",
    "    json_pth = \"JSON_file.json\"\n",
    "\n",
    "    with open(json_pth) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    epoch_lst = [\"results\"]\n",
    "\n",
    "    for epoch_dir in epoch_lst:\n",
    "\n",
    "        refedit_pth = f\"refedit_final_512/{epoch_dir}\"\n",
    "        viescore_pth = f\"viescore/{epoch_dir}\"\n",
    "        os.makedirs(f\"{ckpt_pth}/{viescore_pth}\", exist_ok=True)\n",
    "        os.makedirs(f\"{ckpt_pth}/{viescore_pth}/easy_512\", exist_ok=True)\n",
    "        os.makedirs(f\"{ckpt_pth}/{viescore_pth}/hard_512\", exist_ok=True)\n",
    "\n",
    "        for dir in [\"easy_512\", \"hard_512\"]:\n",
    "            imgs = os.listdir(f\"{ckpt_pth}/{refedit_pth}/{dir}\")\n",
    "            for img in imgs:\n",
    "                img_lst = img.split(\"_\")\n",
    "                initial_img = f\"{dir}/{img_lst[0]}_{img_lst[1]}.jpg\"\n",
    "\n",
    "                masked_img = f\"final_benchmark/{initial_img}\"\n",
    "\n",
    "                # read the img and it is the last 512 x 512 img - code works for both PnPInversion evaluation script outputs and huggingface pipeline outputs\n",
    "                edited_img = f\"{dir}/{img}\"\n",
    "                edited_img_full_pth = f\"{ckpt_pth}/{refedit_pth}/{edited_img}\"\n",
    "                edited_image = Image.open(edited_img_full_pth)\n",
    "                edited_image = edited_image.crop((edited_image.size[0] - 512, edited_image.size[1] - 512, edited_image.size[0], edited_image.size[1])) \n",
    "                edited_image.save(f\"{ckpt_pth}/{viescore_pth}/{initial_img}\")\n",
    "                # get the mask\n",
    "                for idx in data:\n",
    "                    if data[idx]['image_path'] == initial_img:\n",
    "                        mask = data[idx]['mask']\n",
    "                        break\n",
    "\n",
    "                mask_array = mask_decode(mask, masked_img)\n",
    "\n",
    "                # create masked edited image\n",
    "                masked_edited = Image.fromarray(np.array(edited_image) * mask_array[:,:,None])\n",
    "\n",
    "                masked_edited_save_pth = f\"{ckpt_pth}/{viescore_pth}/{initial_img}\".replace(\".jpg\", \"_masked.jpg\")\n",
    "\n",
    "                masked_edited.save(masked_edited_save_pth)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a professional digital artist. You will have to evaluate the effectiveness of the AI-edited image(s) based on the given rules. You will have to give your output in this way (Keep your reasoning concise and short.):\n",
      "{\n",
      "\"score\" : [...],\n",
      "\"reasoning\" : \"...\"\n",
      "}\n",
      "\n",
      "and don’t output anything else.\n",
      "Two images will be provided: The first being the original image selected from COCO dataset and the second being an AI edited version of the first. The objective is to evaluate how successfully the editing instruction has been executed in the second image. Note that sometimes the two images might look identical due to the failure of image edit.\n",
      "Both the original image and the edited image are masked images since the image contains multiple objects and we want you to only focus on the intended object.\n",
      "\n",
      "From a scale 0 to 10:\n",
      "A score from 0 to 10 will be given based on the success of the editing.\n",
      "- 0 indicates that the scene in the edited image does not follow the editing instruction at all. \n",
      "- 10 indicates that the scene in the edited image follow the editing instruction text perfectly.\n",
      "\n",
      "A second score from 0 to 10 will rate the degree of overediting in the second image.\n",
      "- 0 indicates that the scene in the edited image is completely different from the original. \n",
      "- 10 indicates that the edited image can be recognized as a minimal edited yet effective version of original.\n",
      "\n",
      "Put the score in a list such that output score = [score1, score2], where ’score1’ evaluates the editing success and ’score2’ evaluates the degree of overediting.\n",
      "\n",
      "Editing instruction:\n"
     ]
    }
   ],
   "source": [
    "sc_score_pth = \"sc_score.txt\"\n",
    "\n",
    "with open(sc_score_pth, 'r') as file:\n",
    "    sc_score = file.read()\n",
    "\n",
    "print(sc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "client = OpenAI(\n",
    "    api_key=\"API-KEY\"\n",
    ")\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def get_response(img_pth1, img_pth2, txt):\n",
    "    base64_image1 = encode_image(img_pth1)\n",
    "    base64_image2 = encode_image(img_pth2)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": txt,\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image1}\"},\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image2}\"},\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:55<00:00,  1.18s/it]\n",
      "100%|██████████| 200/200 [03:55<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "ckpt_pth = \"EDITED_IMAGES\"\n",
    "masked_initial_img_dir = \"MASKED_ORIGINALS\"\n",
    "json_pth = \"JSON_file.json\"\n",
    "\n",
    "with open(json_pth) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "name_to_idx = {}\n",
    "\n",
    "for idx in data:\n",
    "    name_to_idx[data[idx]['image_path']] = idx\n",
    "\n",
    "output = {}\n",
    "\n",
    "for dir in [\"easy_512\", \"hard_512\"]:\n",
    "    imgs = os.listdir(f\"{ckpt_pth}/{dir}\")\n",
    "\n",
    "    assert len(imgs) == 200\n",
    "\n",
    "    for img_name in tqdm(imgs):\n",
    "        if \"_masked\" in img_name:\n",
    "            continue\n",
    "        \n",
    "        masked_initial_img_pth = f\"{masked_initial_img_dir}/{dir}/{img_name}\"\n",
    "\n",
    "        masked_edited_img_pth = f\"{ckpt_pth}/{dir}/{img_name.replace('.jpg', '_masked.jpg')}\"\n",
    "\n",
    "        img_id = name_to_idx[f\"{dir}/{img_name}\"]\n",
    "\n",
    "        editing_instruction = data[str(img_id)]['edit_ins_single'] # we use the manually created edit_ins_single (editing instruction just for the masked image) as the editing instruction. Example: \"Add a red hat to the left person\" is changed to \"Add a red hat to the perosn\" since the masked image is only for the left person.\n",
    "\n",
    "        txt_input = f\"{sc_score} {editing_instruction}\"\n",
    "\n",
    "        res = get_response(masked_initial_img_pth, masked_edited_img_pth, txt_input)\n",
    "\n",
    "        try:\n",
    "            output[img_id] = json.loads(res)\n",
    "        except:\n",
    "            output[img_id] = res\n",
    "\n",
    "with open(f\"{ckpt_pth}/sc_output.json\", 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a professional digital artist. You will have to evaluate the effectiveness of the AI-edited image.\n",
      "Two images will be provided: The first being the original image selected from COCO dataset and the second being an AI edited version of the first. So you may not worry about privacy or confidentiality.\n",
      "\n",
      "You must focus solely on the technical quality and artifacts in the edited image, and **do not consider whether the context is natural or not**.\n",
      "\n",
      "Your evaluation should focus on:\n",
      "- Distortions\n",
      "- Unusual body parts or proportions\n",
      "- Unnatural Object Shapes\n",
      "\n",
      "Rate the edited image on a scale from 0 to 10, where:\n",
      "- 0 indicates significant AI-artifacts.\n",
      "- 10 indicates an artifact-free image.\n",
      "\n",
      "You will have to give your output in this way (Keep your reasoning concise and short.): \n",
      "{\n",
      "\"score\": ...,\n",
      "\"reasoning\": \"...\"\n",
      "}\n",
      "\n",
      "and don’t output anything else.\n"
     ]
    }
   ],
   "source": [
    "pq_score_pth = \"pq_score.txt\"\n",
    "\n",
    "with open(pq_score_pth, 'r') as file:\n",
    "    pq_score = file.read()\n",
    "\n",
    "print(pq_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [04:18<00:00,  1.29s/it]\n",
      "100%|██████████| 200/200 [04:23<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "ckpt_pth = \"EDITED_IMAGES\"\n",
    "initial_img_dir = \"ORIGINALS\"\n",
    "json_pth = \"JSON_file.json\"\n",
    "\n",
    "with open(json_pth) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "name_to_idx = {}\n",
    "\n",
    "for idx in data:\n",
    "    name_to_idx[data[idx]['image_path']] = idx\n",
    "\n",
    "output = {}\n",
    "\n",
    "for dir in [\"easy_512\", \"hard_512\"]:\n",
    "    imgs = os.listdir(f\"{ckpt_pth}/{dir}\")\n",
    "\n",
    "    assert len(imgs) == 200\n",
    "\n",
    "    for img_name in tqdm(imgs):\n",
    "        if \"_masked\" in img_name:\n",
    "            continue\n",
    "        \n",
    "        initial_img_pth = f\"{initial_img_dir}/{dir}/{img_name}\"\n",
    "\n",
    "        edited_img_pth = f\"{ckpt_pth}/{dir}/{img_name}\"\n",
    "\n",
    "        img_id = name_to_idx[f\"{dir}/{img_name}\"]\n",
    "\n",
    "        txt_input = f\"{pq_score}\"\n",
    "\n",
    "        res = get_response(initial_img_pth, edited_img_pth, txt_input)\n",
    "\n",
    "        try:\n",
    "            output[img_id] = json.loads(res)\n",
    "        except:\n",
    "            output[img_id] = res\n",
    "\n",
    "with open(f\"{ckpt_pth}/pq_output.json\", 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "\n",
    "def return_vie_score_refedit(pth):\n",
    "    sc_pth = f\"{pth}/sc_output.json\"\n",
    "    pq_pth = f\"{pth}/pq_output.json\"\n",
    "\n",
    "    with open(sc_pth) as f:\n",
    "        sc_data = json.load(f)\n",
    "\n",
    "    # print(len(sc_data))\n",
    "\n",
    "    with open(pq_pth) as f:\n",
    "        pq_data = json.load(f)\n",
    "\n",
    "    assert len(sc_data) == 200\n",
    "    assert len(pq_data) == 200\n",
    "\n",
    "    sc1_easy = 0\n",
    "    sc2_easy = 0\n",
    "    sc_easy = 0\n",
    "    pq_easy = 0\n",
    "    o_easy = 0\n",
    "\n",
    "    sc1_hard = 0\n",
    "    sc2_hard = 0\n",
    "    sc_hard = 0\n",
    "    pq_hard = 0\n",
    "    o_hard = 0\n",
    "\n",
    "    for idx in sc_data:\n",
    "        # print(idx)\n",
    "        sc1 = sc_data[idx][\"score\"][0]\n",
    "        sc2 = sc_data[idx][\"score\"][1]\n",
    "\n",
    "\n",
    "        pq = pq_data[idx][\"score\"]\n",
    "\n",
    "        sc = min(sc1, sc2)\n",
    "\n",
    "        o = np.sqrt(sc * pq)\n",
    "\n",
    "        if int(idx) < 100:\n",
    "            sc1_easy += sc1\n",
    "            sc2_easy += sc2\n",
    "            sc_easy += sc\n",
    "            pq_easy += pq\n",
    "            o_easy += o\n",
    "        else:\n",
    "            sc1_hard += sc1\n",
    "            sc2_hard += sc2\n",
    "            sc_hard += sc\n",
    "            pq_hard += pq\n",
    "            o_hard += o\n",
    "\n",
    "    # return avg results\n",
    "    easy_vals = f\"{sc1_easy/100:.2f}, {sc2_easy/100:.2f}, {sc_easy/100:.2f}, {pq_easy/100:.2f}, {o_easy/100:.2f}\"\n",
    "    hard_vals = f\"{sc1_hard/100:.2f}, {sc2_hard/100:.2f}, {sc_hard/100:.2f}, {pq_hard/100:.2f}, {o_hard/100:.2f}\"\n",
    "\n",
    "    return easy_vals , hard_vals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
